{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this section to suppress warnings generated by the code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Import the necessary libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression as SparkLogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Below are needed for Sequential Feature Selector\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LogisticRegression as SKlearnLogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 17:59:48 WARN Utils: Your hostname, thinkpad-t14-g3 resolves to a loopback address: 127.0.1.1; using 172.16.1.182 instead (on interface wlp2s0)\n",
      "24/05/15 17:59:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ruddy/anaconda3/envs/spyder-env/lib/python3.11/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "24/05/15 17:59:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Step 2. Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Logistic Regression using Spark ML\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Area: integer (nullable = true)\n",
      " |-- Perimeter: double (nullable = true)\n",
      " |-- MajorAxisLength: double (nullable = true)\n",
      " |-- MinorAxisLength: double (nullable = true)\n",
      " |-- AspectRation: double (nullable = true)\n",
      " |-- Eccentricity: double (nullable = true)\n",
      " |-- ConvexArea: integer (nullable = true)\n",
      " |-- EquivDiameter: double (nullable = true)\n",
      " |-- Extent: double (nullable = true)\n",
      " |-- Solidity: double (nullable = true)\n",
      " |-- roundness: double (nullable = true)\n",
      " |-- Compactness: double (nullable = true)\n",
      " |-- ShapeFactor1: double (nullable = true)\n",
      " |-- ShapeFactor2: double (nullable = true)\n",
      " |-- ShapeFactor3: double (nullable = true)\n",
      " |-- ShapeFactor4: double (nullable = true)\n",
      " |-- Class: string (nullable = true)\n",
      "\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+\n",
      "| Area|Perimeter|MajorAxisLength|MinorAxisLength|AspectRation|Eccentricity|ConvexArea|EquivDiameter|     Extent|   Solidity|  roundness|Compactness|ShapeFactor1|ShapeFactor2|ShapeFactor3|ShapeFactor4|Class|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+\n",
      "|28395|  610.291|    208.1781167|     173.888747| 1.197191424| 0.549812187|     28715|  190.1410973|0.763922518|0.988855999|0.958027126|0.913357755| 0.007331506| 0.003147289| 0.834222388| 0.998723889|SEKER|\n",
      "|28734|  638.018|    200.5247957|    182.7344194| 1.097356461| 0.411785251|     29172|  191.2727505|0.783968133|0.984985603|0.887033637|0.953860842| 0.006978659| 0.003563624| 0.909850506| 0.998430331|SEKER|\n",
      "|29380|   624.11|    212.8261299|    175.9311426| 1.209712656| 0.562727317|     29690|  193.4109041|0.778113248|0.989558774|0.947849473|0.908774239| 0.007243912| 0.003047733| 0.825870617| 0.999066137|SEKER|\n",
      "|30008|  645.884|     210.557999|    182.5165157| 1.153638059| 0.498615976|     30724|  195.4670618|0.782681273|0.976695743|0.903936374|0.928328835| 0.007016729| 0.003214562| 0.861794425| 0.994198849|SEKER|\n",
      "|30140|  620.134|    201.8478822|    190.2792788|  1.06079802| 0.333679658|     30417|   195.896503|0.773098035| 0.99089325|0.984877069|0.970515523|  0.00669701| 0.003664972| 0.941900381| 0.999166059|SEKER|\n",
      "+-----+---------+---------------+---------------+------------+------------+----------+-------------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3. Read the data from a CSV file\n",
    "sdf = spark.read.csv(\"sources/drybeans.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# print the schema\n",
    "sdf.printSchema()\n",
    "# show top 5 rows from the dataframe\n",
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  6.0|  522|\n",
      "|  5.0| 1322|\n",
      "|  4.0| 1630|\n",
      "|  3.0| 1928|\n",
      "|  2.0| 2027|\n",
      "|  1.0| 2636|\n",
      "|  0.0| 3546|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Step 4. Data Preprocessing\n",
    "# Convert Class column from string to numerical values (this will be our target column)\n",
    "indexer = StringIndexer(inputCol=\"Class\", outputCol=\"label\")\n",
    "sdf = indexer.fit(sdf).transform(sdf)\n",
    "\n",
    "# Print the value counts for the target column 'label'\n",
    "sdf.groupBy('label').count().orderBy('count').show()\n",
    "\n",
    "# Drop empty rows\n",
    "sdf = sdf.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will perform cross validation using Sequential Feature Selector (SFS) from mlxtend in order to select the features. For that reason, the sample data will be converted to Pandas. And since the data size is small here, we can easily use 80%-100% of the Spark dataframe for the sample size. However, if you plan to use the same SFS for a much larger dataset, you should consider using a smaller percentage (or different methods) to get the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in original DataFrame:  13611\n",
      "Total rows in sampled DataFrame:  10898\n"
     ]
    }
   ],
   "source": [
    "# Step 5. Sample the data for cross validation\n",
    "# Note 1: No need to reduce the data size for a sample if it's a small dataset, but below we do so for demonstration purposes\n",
    "# Note 2: You should get a smaller sample size if the Spark DataFrame is too large. But for this example, we will use 80% sample size\n",
    "sampled_data = sdf.sample(False, 0.8)\n",
    "\n",
    "# Print total number of rows in the original and sampled data\n",
    "print(\"Total rows in original DataFrame: \", sdf.count())\n",
    "print(\"Total rows in sampled DataFrame: \", sampled_data.count())\n",
    "\n",
    "# Drop the 'Class' column from the sampled data since it's a string column which is not needed for our testing\n",
    "sampled_data = sampled_data.drop('Class')\n",
    "\n",
    "# Convert the sampled data to Pandas DataFrame so that we can use it for cross validation in the next step\n",
    "pandas_df = sampled_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4, Cross-Validated Accuracy: 0.847867719810872\n",
      "Number of features: 5, Cross-Validated Accuracy: 0.8482349028045016\n",
      "Number of features: 6, Cross-Validated Accuracy: 0.8480495219168797\n",
      "Best number of features: 5, with Accuracy score: 0.8482349028045016\n",
      "Selected features for the best result: ['Perimeter', 'MajorAxisLength', 'EquivDiameter', 'ShapeFactor1', 'ShapeFactor2']\n"
     ]
    }
   ],
   "source": [
    "# Step 6. Perform cross validation using Sequential Feature Selector\n",
    "# X is your matrix of features and y is the target variable\n",
    "X = pandas_df.drop('label', axis=1)\n",
    "y = pandas_df['label']\n",
    "\n",
    "# Create a Logistic Regression model. Adjust the solver and max_iter as needed\n",
    "lr = SKlearnLogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# Define the range of features to consider, let's choose between 4-6 features\n",
    "k_features_range = range(4, 7)\n",
    "\n",
    "# Dictionary to hold the results and selected features\n",
    "results = {}\n",
    "selected_features = {}\n",
    "\n",
    "for k in k_features_range:\n",
    "    sfs = SFS(lr, \n",
    "              k_features=k, \n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              scoring='accuracy',\n",
    "              cv=5)\n",
    "\n",
    "    # Fit the model\n",
    "    sfs.fit(X, y)\n",
    "    \n",
    "    # Store the mean cross-validated score\n",
    "    mean_score = np.mean(cross_val_score(lr, X.iloc[:, list(sfs.k_feature_idx_)], y, cv=5, scoring='accuracy'))\n",
    "    results[k] = mean_score\n",
    "    selected_features[k] = X.columns[list(sfs.k_feature_idx_)].tolist()\n",
    "    print(f'Number of features: {k}, Cross-Validated Accuracy: {mean_score}')\n",
    "\n",
    "# Find the number of features with the best mean score\n",
    "best_feature_count = max(results, key=results.get)\n",
    "best_score = results[best_feature_count]\n",
    "best_features = selected_features[best_feature_count]\n",
    "\n",
    "print(f'Best number of features: {best_feature_count}, with Accuracy score: {best_score}')\n",
    "print(f'Selected features for the best result: {best_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7. Select the columns printed from the previous step as the features, and create a vector assembler\n",
    "inputCols = best_features\n",
    "\n",
    "assembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8. Scale the features using Standard Scaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9. Create the Spark Logistic Regression model\n",
    "classifier = SparkLogisticRegression(featuresCol=\"scaledFeatures\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10. Build the pipeline with the correct order\n",
    "pipeline = Pipeline(stages=[assembler, scaler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11. Split the transformed data into training and test sets\n",
    "(training_data, testing_data) = sdf.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/15 18:00:47 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "24/05/15 18:00:47 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    }
   ],
   "source": [
    "# Step 12. Fit the model using the training data\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Ignore the warning messages (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13. Evaluate the model using the testing data\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[524.736,183.9652...|  0.0|       0.0|\n",
      "|[533.701,185.3819...|  0.0|       0.0|\n",
      "|[530.825,191.9944...|  0.0|       0.0|\n",
      "|[535.436,192.5302...|  0.0|       0.0|\n",
      "|[538.454,196.5372...|  0.0|       0.0|\n",
      "|[558.343,208.5232...|  0.0|       0.0|\n",
      "|[545.616,191.6489...|  0.0|       0.0|\n",
      "|[543.295,201.3477...|  0.0|       0.0|\n",
      "|[551.696,204.7763...|  0.0|       0.0|\n",
      "|[557.585,199.1229...|  0.0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 14. Select and display the predictions alongside the actual values for the target column\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.907467940658788\n",
      "Precision = 0.907893570993255\n",
      "Recall = 0.907467940658788\n",
      "F1 score =  0.9075041112512361\n"
     ]
    }
   ],
   "source": [
    "# Step 15. Evaluate the model performance further: Accuracy, Precision, Recall, and F1 score\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy =\", accuracy)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator.evaluate(predictions)\n",
    "print(\"Precision =\", precision)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "recall = evaluator.evaluate(predictions)\n",
    "print(\"Recall =\", recall)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "print(\"F1 score = \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16. Stop the SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
