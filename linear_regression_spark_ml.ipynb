{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this section to suppress warnings generated by the code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Import the necessary libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression as SparkLR\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from functools import reduce\n",
    "from operator import and_\n",
    "\n",
    "# Below are needed for Sequential Feature Selector\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression as SKlearnLR\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Linear Regression using Spark ML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- MSSubClass: integer (nullable = true)\n",
      " |-- MSZoning: string (nullable = true)\n",
      " |-- LotFrontage: string (nullable = true)\n",
      " |-- LotArea: integer (nullable = true)\n",
      " |-- Street: string (nullable = true)\n",
      " |-- Alley: string (nullable = true)\n",
      " |-- LotShape: string (nullable = true)\n",
      " |-- LandContour: string (nullable = true)\n",
      " |-- Utilities: string (nullable = true)\n",
      " |-- LotConfig: string (nullable = true)\n",
      " |-- LandSlope: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Condition1: string (nullable = true)\n",
      " |-- Condition2: string (nullable = true)\n",
      " |-- BldgType: string (nullable = true)\n",
      " |-- HouseStyle: string (nullable = true)\n",
      " |-- OverallQual: integer (nullable = true)\n",
      " |-- OverallCond: integer (nullable = true)\n",
      " |-- YearBuilt: integer (nullable = true)\n",
      " |-- YearRemodAdd: integer (nullable = true)\n",
      " |-- RoofStyle: string (nullable = true)\n",
      " |-- RoofMatl: string (nullable = true)\n",
      " |-- Exterior1st: string (nullable = true)\n",
      " |-- Exterior2nd: string (nullable = true)\n",
      " |-- MasVnrType: string (nullable = true)\n",
      " |-- MasVnrArea: string (nullable = true)\n",
      " |-- ExterQual: string (nullable = true)\n",
      " |-- ExterCond: string (nullable = true)\n",
      " |-- Foundation: string (nullable = true)\n",
      " |-- BsmtQual: string (nullable = true)\n",
      " |-- BsmtCond: string (nullable = true)\n",
      " |-- BsmtExposure: string (nullable = true)\n",
      " |-- BsmtFinType1: string (nullable = true)\n",
      " |-- BsmtFinSF1: string (nullable = true)\n",
      " |-- BsmtFinType2: string (nullable = true)\n",
      " |-- BsmtFinSF2: string (nullable = true)\n",
      " |-- BsmtUnfSF: string (nullable = true)\n",
      " |-- TotalBsmtSF: string (nullable = true)\n",
      " |-- Heating: string (nullable = true)\n",
      " |-- HeatingQC: string (nullable = true)\n",
      " |-- CentralAir: string (nullable = true)\n",
      " |-- Electrical: string (nullable = true)\n",
      " |-- 1stFlrSF: integer (nullable = true)\n",
      " |-- 2ndFlrSF: integer (nullable = true)\n",
      " |-- LowQualFinSF: integer (nullable = true)\n",
      " |-- GrLivArea: integer (nullable = true)\n",
      " |-- BsmtFullBath: string (nullable = true)\n",
      " |-- BsmtHalfBath: string (nullable = true)\n",
      " |-- FullBath: integer (nullable = true)\n",
      " |-- HalfBath: integer (nullable = true)\n",
      " |-- BedroomAbvGr: integer (nullable = true)\n",
      " |-- KitchenAbvGr: integer (nullable = true)\n",
      " |-- KitchenQual: string (nullable = true)\n",
      " |-- TotRmsAbvGrd: integer (nullable = true)\n",
      " |-- Functional: string (nullable = true)\n",
      " |-- Fireplaces: integer (nullable = true)\n",
      " |-- FireplaceQu: string (nullable = true)\n",
      " |-- GarageType: string (nullable = true)\n",
      " |-- GarageYrBlt: string (nullable = true)\n",
      " |-- GarageFinish: string (nullable = true)\n",
      " |-- GarageCars: string (nullable = true)\n",
      " |-- GarageArea: string (nullable = true)\n",
      " |-- GarageQual: string (nullable = true)\n",
      " |-- GarageCond: string (nullable = true)\n",
      " |-- PavedDrive: string (nullable = true)\n",
      " |-- WoodDeckSF: integer (nullable = true)\n",
      " |-- OpenPorchSF: integer (nullable = true)\n",
      " |-- EnclosedPorch: integer (nullable = true)\n",
      " |-- 3SsnPorch: integer (nullable = true)\n",
      " |-- ScreenPorch: integer (nullable = true)\n",
      " |-- PoolArea: integer (nullable = true)\n",
      " |-- PoolQC: string (nullable = true)\n",
      " |-- Fence: string (nullable = true)\n",
      " |-- MiscFeature: string (nullable = true)\n",
      " |-- MiscVal: integer (nullable = true)\n",
      " |-- MoSold: integer (nullable = true)\n",
      " |-- YrSold: integer (nullable = true)\n",
      " |-- SaleType: string (nullable = true)\n",
      " |-- SaleCondition: string (nullable = true)\n",
      " |-- SalePrice: integer (nullable = true)\n",
      "\n",
      "+---+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+---------+\n",
      "| Id|MSSubClass|MSZoning|LotFrontage|LotArea|Street|Alley|LotShape|LandContour|Utilities|LotConfig|LandSlope|Neighborhood|Condition1|Condition2|BldgType|HouseStyle|OverallQual|OverallCond|YearBuilt|YearRemodAdd|RoofStyle|RoofMatl|Exterior1st|Exterior2nd|MasVnrType|MasVnrArea|ExterQual|ExterCond|Foundation|BsmtQual|BsmtCond|BsmtExposure|BsmtFinType1|BsmtFinSF1|BsmtFinType2|BsmtFinSF2|BsmtUnfSF|TotalBsmtSF|Heating|HeatingQC|CentralAir|Electrical|1stFlrSF|2ndFlrSF|LowQualFinSF|GrLivArea|BsmtFullBath|BsmtHalfBath|FullBath|HalfBath|BedroomAbvGr|KitchenAbvGr|KitchenQual|TotRmsAbvGrd|Functional|Fireplaces|FireplaceQu|GarageType|GarageYrBlt|GarageFinish|GarageCars|GarageArea|GarageQual|GarageCond|PavedDrive|WoodDeckSF|OpenPorchSF|EnclosedPorch|3SsnPorch|ScreenPorch|PoolArea|PoolQC|Fence|MiscFeature|MiscVal|MoSold|YrSold|SaleType|SaleCondition|SalePrice|\n",
      "+---+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+---------+\n",
      "|  1|        60|      RL|         65|   8450|  Pave|   NA|     Reg|        Lvl|   AllPub|   Inside|      Gtl|     CollgCr|      Norm|      Norm|    1Fam|    2Story|          7|          5|     2003|        2003|    Gable| CompShg|    VinylSd|    VinylSd|   BrkFace|       196|       Gd|       TA|     PConc|      Gd|      TA|          No|         GLQ|       706|         Unf|         0|      150|        856|   GasA|       Ex|         Y|     SBrkr|     856|     854|           0|     1710|           1|           0|       2|       1|           3|           1|         Gd|           8|       Typ|         0|         NA|    Attchd|       2003|         RFn|         2|       548|        TA|        TA|         Y|         0|         61|            0|        0|          0|       0|    NA|   NA|         NA|      0|     2|  2008|      WD|       Normal|   208500|\n",
      "|  2|        20|      RL|         80|   9600|  Pave|   NA|     Reg|        Lvl|   AllPub|      FR2|      Gtl|     Veenker|     Feedr|      Norm|    1Fam|    1Story|          6|          8|     1976|        1976|    Gable| CompShg|    MetalSd|    MetalSd|      None|         0|       TA|       TA|    CBlock|      Gd|      TA|          Gd|         ALQ|       978|         Unf|         0|      284|       1262|   GasA|       Ex|         Y|     SBrkr|    1262|       0|           0|     1262|           0|           1|       2|       0|           3|           1|         TA|           6|       Typ|         1|         TA|    Attchd|       1976|         RFn|         2|       460|        TA|        TA|         Y|       298|          0|            0|        0|          0|       0|    NA|   NA|         NA|      0|     5|  2007|      WD|       Normal|   181500|\n",
      "|  3|        60|      RL|         68|  11250|  Pave|   NA|     IR1|        Lvl|   AllPub|   Inside|      Gtl|     CollgCr|      Norm|      Norm|    1Fam|    2Story|          7|          5|     2001|        2002|    Gable| CompShg|    VinylSd|    VinylSd|   BrkFace|       162|       Gd|       TA|     PConc|      Gd|      TA|          Mn|         GLQ|       486|         Unf|         0|      434|        920|   GasA|       Ex|         Y|     SBrkr|     920|     866|           0|     1786|           1|           0|       2|       1|           3|           1|         Gd|           6|       Typ|         1|         TA|    Attchd|       2001|         RFn|         2|       608|        TA|        TA|         Y|         0|         42|            0|        0|          0|       0|    NA|   NA|         NA|      0|     9|  2008|      WD|       Normal|   223500|\n",
      "|  4|        70|      RL|         60|   9550|  Pave|   NA|     IR1|        Lvl|   AllPub|   Corner|      Gtl|     Crawfor|      Norm|      Norm|    1Fam|    2Story|          7|          5|     1915|        1970|    Gable| CompShg|    Wd Sdng|    Wd Shng|      None|         0|       TA|       TA|    BrkTil|      TA|      Gd|          No|         ALQ|       216|         Unf|         0|      540|        756|   GasA|       Gd|         Y|     SBrkr|     961|     756|           0|     1717|           1|           0|       1|       0|           3|           1|         Gd|           7|       Typ|         1|         Gd|    Detchd|       1998|         Unf|         3|       642|        TA|        TA|         Y|         0|         35|          272|        0|          0|       0|    NA|   NA|         NA|      0|     2|  2006|      WD|      Abnorml|   140000|\n",
      "|  5|        60|      RL|         84|  14260|  Pave|   NA|     IR1|        Lvl|   AllPub|      FR2|      Gtl|     NoRidge|      Norm|      Norm|    1Fam|    2Story|          8|          5|     2000|        2000|    Gable| CompShg|    VinylSd|    VinylSd|   BrkFace|       350|       Gd|       TA|     PConc|      Gd|      TA|          Av|         GLQ|       655|         Unf|         0|      490|       1145|   GasA|       Ex|         Y|     SBrkr|    1145|    1053|           0|     2198|           1|           0|       2|       1|           4|           1|         Gd|           9|       Typ|         1|         TA|    Attchd|       2000|         RFn|         3|       836|        TA|        TA|         Y|       192|         84|            0|        0|          0|       0|    NA|   NA|         NA|      0|    12|  2008|      WD|       Normal|   250000|\n",
      "+---+----------+--------+-----------+-------+------+-----+--------+-----------+---------+---------+---------+------------+----------+----------+--------+----------+-----------+-----------+---------+------------+---------+--------+-----------+-----------+----------+----------+---------+---------+----------+--------+--------+------------+------------+----------+------------+----------+---------+-----------+-------+---------+----------+----------+--------+--------+------------+---------+------------+------------+--------+--------+------------+------------+-----------+------------+----------+----------+-----------+----------+-----------+------------+----------+----------+----------+----------+----------+----------+-----------+-------------+---------+-----------+--------+------+-----+-----------+-------+------+------+--------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3. Read the data from a CSV file\n",
    "sdf = spark.read.csv(\"sources/housing.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# print the schema\n",
    "sdf.printSchema()\n",
    "# show top 5 rows from the dataframe\n",
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Data Cleaning\n",
    "\n",
    "# Clean up empty values\n",
    "sdf = sdf.dropna()\n",
    "\n",
    "# Drop the 'Id' column since it is not relevant, it's just an index\n",
    "sdf = sdf.drop('Id')\n",
    "\n",
    "# Get a list of non-string column names\n",
    "non_string_columns = [name for name, dtype in sdf.dtypes if dtype != 'string']\n",
    "\n",
    "# Define a list to hold the outlier filtering conditions\n",
    "conditions = []\n",
    "\n",
    "# Loop over each non-string column\n",
    "for c in non_string_columns:\n",
    "    # Calculate the lower and upper bounds for the column\n",
    "    quantiles = sdf.approxQuantile(c, [0.25, 0.75], 0.05)\n",
    "    IQR = quantiles[1] - quantiles[0]\n",
    "    lower_bound = quantiles[0] - 1.5 * IQR\n",
    "    upper_bound = quantiles[1] + 1.5 * IQR\n",
    "\n",
    "    # Add a condition to filter out outliers in the column\n",
    "    conditions.append((col(c) >= lower_bound) & (col(c) <= upper_bound))\n",
    "\n",
    "# Apply the conditions to the DataFrame and then select only the non-string columns\n",
    "sdf = sdf.filter(reduce(and_, conditions))\n",
    "sdf = sdf.select(*[col(c) for c in non_string_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will perform cross validation using Sequential Feature Selector (SFS) from mlxtend in order to select the features. For that reason, the sample data will be converted to Pandas. And since the data size is small here, we can easily use 80%-100% of the Spark dataframe for the sample size. However, if you plan to use the same SFS for a much larger dataset, you should consider using a smaller percentage for the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in original DataFrame:  701\n",
      "Total rows in sampled DataFrame:  555\n"
     ]
    }
   ],
   "source": [
    "# Step 5. Sample the data for cross validation\n",
    "# Note 1: No need to reduce the data size for a sample if it's a small dataset, but below we do so for demonstration purposes\n",
    "# Note 2: You should get a smaller sample size if the Spark DataFrame is too large. But for this example, we will use 80% sample size\n",
    "sampled_data = sdf.sample(False, 0.8)\n",
    "\n",
    "# Print total number of rows in the original and sampled data\n",
    "print(\"Total rows in original DataFrame: \", sdf.count())\n",
    "print(\"Total rows in sampled DataFrame: \", sampled_data.count())\n",
    "\n",
    "# Convert the sampled data to Pandas DataFrame so that we can use it for cross validation in the next step\n",
    "pandas_df = sampled_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 1, Cross-Validated R²: 0.7011662983097809\n",
      "Number of features: 2, Cross-Validated R²: 0.7869100553840701\n",
      "Number of features: 3, Cross-Validated R²: 0.8200407779266085\n",
      "Number of features: 4, Cross-Validated R²: 0.8390228524152249\n",
      "Number of features: 5, Cross-Validated R²: 0.8463182205265115\n",
      "Number of features: 6, Cross-Validated R²: 0.8513480786348131\n",
      "Number of features: 7, Cross-Validated R²: 0.8557875656853898\n",
      "Number of features: 8, Cross-Validated R²: 0.8573121290533825\n",
      "Number of features: 9, Cross-Validated R²: 0.8580186863615745\n",
      "Number of features: 10, Cross-Validated R²: 0.8581599057374083\n",
      "Number of features: 11, Cross-Validated R²: 0.8588813795043876\n",
      "Number of features: 12, Cross-Validated R²: 0.8588813795043894\n",
      "Number of features: 13, Cross-Validated R²: 0.8588813795043896\n",
      "Number of features: 14, Cross-Validated R²: 0.8588813795043899\n",
      "Number of features: 15, Cross-Validated R²: 0.8588813795043897\n",
      "Number of features: 16, Cross-Validated R²: 0.8588813795043899\n",
      "Number of features: 17, Cross-Validated R²: 0.8588813795043894\n",
      "Number of features: 18, Cross-Validated R²: 0.8588813795043894\n",
      "Number of features: 19, Cross-Validated R²: 0.8588813795043873\n",
      "Number of features: 20, Cross-Validated R²: 0.8588602197554343\n",
      "Number of features: 21, Cross-Validated R²: 0.858654977302491\n",
      "Number of features: 22, Cross-Validated R²: 0.8583442109069574\n",
      "Number of features: 23, Cross-Validated R²: 0.8580306690141987\n",
      "Number of features: 24, Cross-Validated R²: 0.8575754909547069\n",
      "Number of features: 25, Cross-Validated R²: 0.8567671367560971\n",
      "Best number of features: 14, with R² score: 0.8588813795043899\n",
      "Selected features for the best result: ['LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', '1stFlrSF', 'LowQualFinSF', 'GrLivArea', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch']\n"
     ]
    }
   ],
   "source": [
    "# Step 6. Perform cross validation using Sequential Feature Selector\n",
    "# X is your matrix of features and y is the target variable\n",
    "X = pandas_df.drop('SalePrice', axis=1)\n",
    "y = pandas_df['SalePrice']\n",
    "\n",
    "# Create a linear regression model with scikit-learn\n",
    "lr = SKlearnLR()\n",
    "\n",
    "# Define the range of features to consider\n",
    "k_features_range = range(1, X.shape[1] + 1)  # From 1 to the total number of features in X\n",
    "\n",
    "# Dictionary to hold the results and selected features\n",
    "results = {}\n",
    "selected_features = {}\n",
    "\n",
    "for k in k_features_range:\n",
    "    sfs = SFS(lr, \n",
    "              k_features=k, \n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              scoring='r2',\n",
    "              cv=5)\n",
    "\n",
    "    # Fit the model\n",
    "    sfs.fit(X, y)\n",
    "    \n",
    "    # Store the mean cross-validated score\n",
    "    mean_score = np.mean(cross_val_score(lr, X.iloc[:, list(sfs.k_feature_idx_)], y, cv=5, scoring='r2'))\n",
    "    results[k] = mean_score\n",
    "    selected_features[k] = X.columns[list(sfs.k_feature_idx_)].tolist()\n",
    "    print(f'Number of features: {k}, Cross-Validated R²: {mean_score}')\n",
    "\n",
    "# Find the number of features with the best mean score\n",
    "best_feature_count = max(results, key=results.get)\n",
    "best_score = results[best_feature_count]\n",
    "best_features = selected_features[best_feature_count]\n",
    "\n",
    "print(f'Best number of features: {best_feature_count}, with R² score: {best_score}')\n",
    "print(f'Selected features for the best result: {best_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7. Select the columns printed from the previous step as the features, and create a vector assembler\n",
    "inputCols = best_features\n",
    "\n",
    "assembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8. Scale the features using Standard Scaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9. Create the Spark Linear Regression model\n",
    "lr = SparkLR(featuresCol=\"scaledFeatures\", labelCol=\"SalePrice\", regParam=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10. Build the pipeline with the correct order\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11. Split the transformed data into training and test sets\n",
    "(training_data, testing_data) = sdf.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12. Fit the model using the training data\n",
    "model = pipeline.fit(training_data)\n",
    "\n",
    "# Ignore the warning messages (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13. Evaluate the model using the testing data\n",
    "predictions = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+------------------+\n",
      "|            features|SalePrice|        prediction|\n",
      "+--------------------+---------+------------------+\n",
      "|(14,[0,1,2,3,4,6,...|   117000|107282.41913759708|\n",
      "|(14,[0,1,2,3,4,6,...|   125500|113236.90590411215|\n",
      "|(14,[0,1,2,3,4,6,...|   109500|109106.85799072427|\n",
      "|(14,[0,1,2,3,4,6,...|    72500| 60982.70407183119|\n",
      "|[6853.0,8.0,5.0,2...|   220000|211119.99061907432|\n",
      "|[6951.0,5.0,5.0,1...|   119500|129560.72566998843|\n",
      "|(14,[0,1,2,3,4,6,...|   135000| 144271.7549687547|\n",
      "|[7064.0,5.0,6.0,1...|   135000| 132138.9191642485|\n",
      "|(14,[0,1,2,3,4,6,...|   129900|111205.57309051603|\n",
      "|[7153.0,6.0,5.0,1...|   179200|168970.22361345985|\n",
      "+--------------------+---------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 14. Select and display the predictions alongside the actual values for the target column\n",
    "predictions.select(\"features\", \"SalePrice\", \"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared = 0.8637484612630817\n",
      "RMSE = 17449.469100109724\n",
      "MAE = 13490.09284096485\n"
     ]
    }
   ],
   "source": [
    "# Step 15. Evaluate the model further using R squared, Root Mean Squared Error, and Mean Absolute Error\n",
    "evaluator = RegressionEvaluator(labelCol=\"SalePrice\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R Squared =\", r2)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"SalePrice\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE =\", rmse)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"SalePrice\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(\"MAE =\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 16. Stop the SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
