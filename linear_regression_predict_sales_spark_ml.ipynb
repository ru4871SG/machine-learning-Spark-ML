{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this demonstration, we will use Linear Regression from Spark ML to make sales predictions. Our original csv file (sources/searchterms.csv) contains different search terms for the year 2020, 2021, and 2022. Using this data, we will try to make sales predictions for the year 2023 and 2024 by leveraging the search counts for each search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this section to suppress warnings generated by the code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler, StringIndexer\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"Predict Sales with Linear Regression on Spark ML\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+--------------+\n",
      "|day|month|year|    searchterm|\n",
      "+---+-----+----+--------------+\n",
      "| 12|   11|2020| mobile 6 inch|\n",
      "| 12|   11|2020| mobile latest|\n",
      "| 12|   11|2020|   tablet wifi|\n",
      "| 12|   11|2020|laptop 14 inch|\n",
      "| 12|   11|2020|     mobile 5g|\n",
      "+---+-----+----+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- day: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- searchterm: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the data from the CSV file, preview the data, and print the schema\n",
    "sdf = spark.read.csv(\"sources/searchterms.csv\", header=True, inferSchema=True)\n",
    "\n",
    "sdf.show(5)\n",
    "sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we will use \"searchterm\" column for our target, let's change it to a numerical column\n",
    "indexer = StringIndexer(inputCol=\"searchterm\", outputCol=\"searchtermnum\")\n",
    "sdf = indexer.fit(sdf).transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|         searchterm|count|\n",
      "+-------------------+-----+\n",
      "|          pen drive|  144|\n",
      "|ebooks data science|  410|\n",
      "|     laptop 14 inch|  461|\n",
      "|      gaming laptop|  499|\n",
      "|     tablet 10 inch|  715|\n",
      "|        tablet wifi|  896|\n",
      "|             laptop|  935|\n",
      "|      mobile latest| 1327|\n",
      "|          mobile 5g| 2301|\n",
      "|      mobile 6 inch| 2312|\n",
      "+-------------------+-----+\n",
      "\n",
      "+-------------+-----+\n",
      "|searchtermnum|count|\n",
      "+-------------+-----+\n",
      "|          9.0|  144|\n",
      "|          8.0|  410|\n",
      "|          7.0|  461|\n",
      "|          6.0|  499|\n",
      "|          5.0|  715|\n",
      "|          4.0|  896|\n",
      "|          3.0|  935|\n",
      "|          2.0| 1327|\n",
      "|          1.0| 2301|\n",
      "|          0.0| 2312|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Double check the original \"searchterm\" vs. the numerical version \"searchtermnum\"\n",
    "sdf.groupBy('searchterm').count().orderBy('count').show()\n",
    "sdf.groupBy('searchtermnum').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----+\n",
      "|searchtermnum|searchcount|year|\n",
      "+-------------+-----------+----+\n",
      "|          0.0|        243|2020|\n",
      "|          1.0|        213|2020|\n",
      "|          2.0|        134|2020|\n",
      "|          3.0|         92|2020|\n",
      "|          4.0|         93|2020|\n",
      "+-------------+-----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's use Spark SQL to get the count of each search term\n",
    "sdf.createOrReplaceTempView(\"sdfview\")\n",
    "\n",
    "grouped_sdf = spark.sql(\"SELECT searchtermnum, COUNT(searchtermnum) as searchcount, year FROM sdfview GROUP BY searchtermnum, year ORDER BY year, searchtermnum\")\n",
    "grouped_sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the pipeline using \"searchtermnum\" and \"year\" as features and \"searchcount\" as the target\n",
    "assembler = VectorAssembler(inputCols=[\"searchtermnum\", \"year\"], outputCol=\"features\")\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "lr = LinearRegression(featuresCol=\"scaledFeatures\", labelCol=\"searchcount\", regParam=0.1)\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing data with a 70/30 split\n",
    "(training_data, testing_data) = grouped_sdf.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----+------------+--------------------+------------------+\n",
      "|searchtermnum|searchcount|year|    features|      scaledFeatures|        prediction|\n",
      "+-------------+-----------+----+------------+--------------------+------------------+\n",
      "|          0.0|       1256|2022|[0.0,2022.0]|[0.0,2557.6501715...| 899.7955508879386|\n",
      "|          2.0|        134|2020|[2.0,2020.0]|[0.67386211516186...| 296.8953954371973|\n",
      "|          2.0|        732|2022|[2.0,2022.0]|[0.67386211516186...| 751.3004338201135|\n",
      "|          3.0|         92|2020|[3.0,2020.0]|[1.01079317274279...|222.64783690322656|\n",
      "|          4.0|        314|2021|[4.0,2021.0]|[1.34772423032372...|375.60279756074306|\n",
      "+-------------+-----------+----+------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make the predictions\n",
    "predictions = model.transform(testing_data)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared = 0.809266318611074\n",
      "RMSE = 149.54214708055568\n",
      "MAE = 119.99339563497611\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model further using R squared, Root Mean Squared Error, and Mean Absolute Error\n",
    "evaluator = RegressionEvaluator(labelCol=\"searchcount\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R Squared =\", r2)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"searchcount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE =\", rmse)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"searchcount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(predictions)\n",
    "print(\"MAE =\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+------------+--------------------+------------------+\n",
      "|searchtermnum|year|    features|      scaledFeatures|        prediction|\n",
      "+-------------+----+------------+--------------------+------------------+\n",
      "|          0.0|2023|[0.0,2023.0]|[0.0,2558.9150826...|1126.9980700793676|\n",
      "|          1.0|2023|[1.0,2023.0]|[0.33693105758093...| 1052.750511545455|\n",
      "|          2.0|2023|[2.0,2023.0]|[0.67386211516186...| 978.5029530114844|\n",
      "|          3.0|2023|[3.0,2023.0]|[1.01079317274279...| 904.2553944775718|\n",
      "|          4.0|2023|[4.0,2023.0]|[1.34772423032372...| 830.0078359436011|\n",
      "|          5.0|2023|[5.0,2023.0]|[1.68465528790465...| 755.7602774096886|\n",
      "|          6.0|2023|[6.0,2023.0]|[2.02158634548558...| 681.5127188757178|\n",
      "|          7.0|2023|[7.0,2023.0]|[2.35851740306651...| 607.2651603418053|\n",
      "|          8.0|2023|[8.0,2023.0]|[2.69544846064744...| 533.0176018078928|\n",
      "|          9.0|2023|[9.0,2023.0]|[3.03237951822837...|458.77004327392206|\n",
      "|          0.0|2024|[0.0,2024.0]|[0.0,2560.1799936...|1354.2005892707966|\n",
      "|          1.0|2024|[1.0,2024.0]|[0.33693105758093...| 1279.953030736826|\n",
      "|          2.0|2024|[2.0,2024.0]|[0.67386211516186...|1205.7054722029134|\n",
      "|          3.0|2024|[3.0,2024.0]|[1.01079317274279...|1131.4579136689426|\n",
      "|          4.0|2024|[4.0,2024.0]|[1.34772423032372...|  1057.21035513503|\n",
      "|          5.0|2024|[5.0,2024.0]|[1.68465528790465...| 982.9627966011176|\n",
      "|          6.0|2024|[6.0,2024.0]|[2.02158634548558...| 908.7152380671469|\n",
      "|          7.0|2024|[7.0,2024.0]|[2.35851740306651...| 834.4676795332343|\n",
      "|          8.0|2024|[8.0,2024.0]|[2.69544846064744...| 760.2201209992636|\n",
      "|          9.0|2024|[9.0,2024.0]|[3.03237951822837...| 685.9725624653511|\n",
      "+-------------+----+------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's make sales predictions on the year 2023 and 2024 for each search term\n",
    "new_data = [\n",
    "    Row(searchtermnum=0.0, year=2023),\n",
    "    Row(searchtermnum=1.0, year=2023),\n",
    "    Row(searchtermnum=2.0, year=2023),\n",
    "    Row(searchtermnum=3.0, year=2023),\n",
    "    Row(searchtermnum=4.0, year=2023),\n",
    "    Row(searchtermnum=5.0, year=2023),\n",
    "    Row(searchtermnum=6.0, year=2023),\n",
    "    Row(searchtermnum=7.0, year=2023),\n",
    "    Row(searchtermnum=8.0, year=2023),\n",
    "    Row(searchtermnum=9.0, year=2023),\n",
    "    Row(searchtermnum=0.0, year=2024),\n",
    "    Row(searchtermnum=1.0, year=2024),\n",
    "    Row(searchtermnum=2.0, year=2024),\n",
    "    Row(searchtermnum=3.0, year=2024),\n",
    "    Row(searchtermnum=4.0, year=2024),\n",
    "    Row(searchtermnum=5.0, year=2024),\n",
    "    Row(searchtermnum=6.0, year=2024),\n",
    "    Row(searchtermnum=7.0, year=2024),\n",
    "    Row(searchtermnum=8.0, year=2024),\n",
    "    Row(searchtermnum=9.0, year=2024)\n",
    "]\n",
    "\n",
    "# Convert the list of Rows into a DataFrame\n",
    "sdf_for_new_predictions = spark.createDataFrame(new_data)\n",
    "\n",
    "# Use the existing pipeline model to make predictions on the new data\n",
    "new_predictions = model.transform(sdf_for_new_predictions)\n",
    "\n",
    "# Show the sales predictions for the year 2023 and 2024\n",
    "new_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a local folder\n",
    "base_dir = \"model_storage_\"\n",
    "i = 0\n",
    "while os.path.exists(f\"{base_dir}{str(i).zfill(2)}\"):\n",
    "    i += 1\n",
    "dir_path = f\"{base_dir}{str(i).zfill(2)}\"\n",
    "\n",
    "model.write().save(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the persisted model by loading it back\n",
    "loaded_model = PipelineModel.load(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+----+------------+--------------------+------------------+\n",
      "|searchtermnum|searchcount|year|    features|      scaledFeatures|        prediction|\n",
      "+-------------+-----------+----+------------+--------------------+------------------+\n",
      "|          0.0|       1256|2022|[0.0,2022.0]|[0.0,2557.6501715...| 899.7955508879386|\n",
      "|          2.0|        134|2020|[2.0,2020.0]|[0.67386211516186...| 296.8953954371973|\n",
      "|          2.0|        732|2022|[2.0,2022.0]|[0.67386211516186...| 751.3004338201135|\n",
      "|          3.0|         92|2020|[3.0,2020.0]|[1.01079317274279...|222.64783690322656|\n",
      "|          4.0|        314|2021|[4.0,2021.0]|[1.34772423032372...|375.60279756074306|\n",
      "+-------------+-----------+----+------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------+----+------------+--------------------+------------------+\n",
      "|searchtermnum|year|    features|      scaledFeatures|        prediction|\n",
      "+-------------+----+------------+--------------------+------------------+\n",
      "|          0.0|2023|[0.0,2023.0]|[0.0,2558.9150826...|1126.9980700793676|\n",
      "|          1.0|2023|[1.0,2023.0]|[0.33693105758093...| 1052.750511545455|\n",
      "|          2.0|2023|[2.0,2023.0]|[0.67386211516186...| 978.5029530114844|\n",
      "|          3.0|2023|[3.0,2023.0]|[1.01079317274279...| 904.2553944775718|\n",
      "|          4.0|2023|[4.0,2023.0]|[1.34772423032372...| 830.0078359436011|\n",
      "+-------------+----+------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's use the persisted model and make predictions on test data, to compare with the previous predictions\n",
    "predictions_from_loaded_model = loaded_model.transform(testing_data)\n",
    "new_predictions_from_loaded_model = loaded_model.transform(sdf_for_new_predictions)\n",
    "\n",
    "predictions_from_loaded_model.show(5)\n",
    "new_predictions_from_loaded_model.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
