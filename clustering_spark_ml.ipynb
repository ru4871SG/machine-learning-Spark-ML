{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this section to suppress warnings generated by the code:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Import the necessary libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Clustering with Spark ML\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- area: double (nullable = true)\n",
      " |-- perimeter: double (nullable = true)\n",
      " |-- compactness: double (nullable = true)\n",
      " |-- length of kernel: double (nullable = true)\n",
      " |-- width of kernel: double (nullable = true)\n",
      " |-- asymmetry coefficient: double (nullable = true)\n",
      " |-- length of kernel groove: double (nullable = true)\n",
      "\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "# Step 3. Read the data from a CSV file\n",
    "sdf = spark.read.csv(\"sources/seeds.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# print the schema and the number of records\n",
    "sdf.printSchema()\n",
    "print(sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------\n",
      " area                    | 15.26  \n",
      " perimeter               | 14.84  \n",
      " compactness             | 0.871  \n",
      " length of kernel        | 5.763  \n",
      " width of kernel         | 3.312  \n",
      " asymmetry coefficient   | 2.221  \n",
      " length of kernel groove | 5.22   \n",
      "-RECORD 1-------------------------\n",
      " area                    | 14.88  \n",
      " perimeter               | 14.57  \n",
      " compactness             | 0.8811 \n",
      " length of kernel        | 5.554  \n",
      " width of kernel         | 3.333  \n",
      " asymmetry coefficient   | 1.018  \n",
      " length of kernel groove | 4.956  \n",
      "-RECORD 2-------------------------\n",
      " area                    | 14.29  \n",
      " perimeter               | 14.09  \n",
      " compactness             | 0.905  \n",
      " length of kernel        | 5.291  \n",
      " width of kernel         | 3.337  \n",
      " asymmetry coefficient   | 2.699  \n",
      " length of kernel groove | 4.825  \n",
      "-RECORD 3-------------------------\n",
      " area                    | 13.84  \n",
      " perimeter               | 13.94  \n",
      " compactness             | 0.8955 \n",
      " length of kernel        | 5.324  \n",
      " width of kernel         | 3.379  \n",
      " asymmetry coefficient   | 2.259  \n",
      " length of kernel groove | 4.805  \n",
      "-RECORD 4-------------------------\n",
      " area                    | 16.14  \n",
      " perimeter               | 14.99  \n",
      " compactness             | 0.9034 \n",
      " length of kernel        | 5.658  \n",
      " width of kernel         | 3.562  \n",
      " asymmetry coefficient   | 1.355  \n",
      " length of kernel groove | 5.175  \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4. Data Preview - Show the top 5 rows\n",
    "sdf.show(n=5, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----------+----------------+---------------+---------------------+-----------------------+\n",
      "|area|perimeter|compactness|length of kernel|width of kernel|asymmetry coefficient|length of kernel groove|\n",
      "+----+---------+-----------+----------------+---------------+---------------------+-----------------------+\n",
      "|null|     null|     0.8099|            null|          2.641|                 null|                  5.185|\n",
      "|12.2|     null|     0.8874|            null|           null|                 null|                    5.0|\n",
      "|12.3|    13.34|       null|            null|           null|                5.637|                   null|\n",
      "+----+---------+-----------+----------------+---------------+---------------------+-----------------------+\n",
      "\n",
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       3|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5. Use Spark SQL to check if there are any null values\n",
    "# Get the list of all columns\n",
    "columns = sdf.columns\n",
    "\n",
    "# Create a temporary view\n",
    "sdf.createOrReplaceTempView(\"seeds\")\n",
    "\n",
    "# Find and show rows with any null values\n",
    "rows_with_nulls = spark.sql(\"SELECT * FROM seeds WHERE \" + \" OR \".join([f\"`{col}` IS NULL\" for col in columns]))\n",
    "rows_with_nulls.show()\n",
    "\n",
    "# Count the number of rows with any null values\n",
    "count_rows_with_nulls = spark.sql(\"SELECT COUNT(*) FROM seeds WHERE \" + \" OR \".join([f\"`{col}` IS NULL\" for col in columns]))\n",
    "count_rows_with_nulls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6. Data Cleaning\n",
    "# Previous step showed that there are several rows with many null values, so we need to remove them\n",
    "sdf = sdf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n"
     ]
    }
   ],
   "source": [
    "# Step 7. Verify Data Cleaning\n",
    "# Check the number of records after removing the rows with null values (should be 210)\n",
    "print(sdf.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8. Assemble all columns into a single vector\n",
    "feature_cols = columns\n",
    "\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9. Scale the features using Standard Scaler\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10. Create 4 Clusters\n",
    "number_of_clusters = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11. Create a K-Means clustering model\n",
    "kmeans = KMeans(k = number_of_clusters, featuresCol=\"scaledFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12. Build a pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, kmeans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13. Train the model using the pipeline\n",
    "model = pipeline.fit(sdf)\n",
    "\n",
    "# Ignore warning messages (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14. Make predictions on the dataset\n",
    "predictions = model.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "| area|perimeter|compactness|length of kernel|width of kernel|asymmetry coefficient|length of kernel groove|            features|      scaledFeatures|prediction|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "|15.26|    14.84|      0.871|           5.763|          3.312|                2.221|                   5.22|[15.26,14.84,0.87...|[5.24452795332028...|         0|\n",
      "|14.88|    14.57|     0.8811|           5.554|          3.333|                1.018|                  4.956|[14.88,14.57,0.88...|[5.11393027165175...|         0|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "| area|perimeter|compactness|length of kernel|width of kernel|asymmetry coefficient|length of kernel groove|            features|      scaledFeatures|prediction|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "|16.63|    15.46|     0.8747|           6.053|          3.465|                 2.04|                  5.877|[16.63,15.46,0.87...|[5.71536696354628...|         1|\n",
      "|16.44|    15.25|      0.888|           5.884|          3.505|                1.969|                  5.533|[16.44,15.25,0.88...|[5.65006812271202...|         1|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "| area|perimeter|compactness|length of kernel|width of kernel|asymmetry coefficient|length of kernel groove|            features|      scaledFeatures|prediction|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "|12.72|    13.57|     0.8686|           5.226|          3.049|                4.102|                  4.914|[12.72,13.57,0.86...|[4.37158555479908...|         2|\n",
      "|12.11|    13.47|     0.8392|           5.159|          3.032|                1.502|                  4.519|[12.11,13.47,0.83...|[4.16194190791013...|         2|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "| area|perimeter|compactness|length of kernel|width of kernel|asymmetry coefficient|length of kernel groove|            features|      scaledFeatures|prediction|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "|19.11|    16.26|     0.9081|           6.154|           3.93|                2.936|                  6.079|[19.11,16.26,0.90...|[6.56768867548824...|         3|\n",
      "|20.71|    17.23|     0.8763|           6.579|          3.814|                4.451|                  6.451|[20.71,17.23,0.87...|[7.11757365093467...|         3|\n",
      "+-----+---------+-----------+----------------+---------------+---------------------+-----------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 15. Use Spark SQL to display the prediction results\n",
    "# Create a temporary view\n",
    "predictions.createOrReplaceTempView(\"seeds_predictions\")\n",
    "\n",
    "# Check two rows from each cluster\n",
    "spark.sql(\"SELECT * FROM seeds_predictions WHERE prediction = 0 LIMIT 2\").show()\n",
    "spark.sql(\"SELECT * FROM seeds_predictions WHERE prediction = 1 LIMIT 2\").show()\n",
    "spark.sql(\"SELECT * FROM seeds_predictions WHERE prediction = 2 LIMIT 2\").show()\n",
    "spark.sql(\"SELECT * FROM seeds_predictions WHERE prediction = 3 LIMIT 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|   29|\n",
      "|         3|   48|\n",
      "|         2|   71|\n",
      "|         0|   62|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 16. Display how many records are in each cluster\n",
    "predictions.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 17. Stop the SparkSession\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
